{"id": "56e17e6ee3433e1400422f80", "title": "Computational_complexity_theory", "context": "To further highlight the difference between a problem and an instance, consider the following instance of the decision version of the traveling salesman problem: Is there a route of at most 2000 kilometres passing through all of Germany's 15 largest cities? The quantitative answer to this particular problem instance is of little use for solving other instances of the problem, such as asking for a round trip through all sites in Milan whose total length is at most 10 km. For this reason, complexity theory addresses computational problems and not particular problem instances.", "question": "What is one example of an instance that the quantitative answer to the traveling salesman problem fails to answer?", "answers": {"text": ["round trip through all sites in Milan", "asking for a round trip through all sites in Milan whose total length is at most 10 km", "a round trip through all sites in Milan whose total length is at most 10 km"], "answer_start": [400, 387, 398]}, "predicted_answer": "asking for a round trip through all sites in Milan"}
{"id": "56e17e6ee3433e1400422f80-high-conf-turk0", "title": "Computational_complexity_theory", "context": "To further highlight the difference between a problem and an instance, consider the following instance of the decision version of the traveling salesman problem: Is there a route of at most 2000 kilometres passing through all of Germany's 15 largest cities? The quantitative answer to this particular problem instance is of little use for solving other instances of the problem, such as asking for a round trip through all sites in Milan whose total length is at most 10 km. For this reason, complexity theory addresses computational problems and not particular problem instances. Central Park is one example of an instance where the qualitative answer to the traveling salesman problem fails.", "question": "What is one example of an instance that the quantitative answer to the traveling salesman problem fails to answer?", "answers": {"text": ["round trip through all sites in Milan", "asking for a round trip through all sites in Milan whose total length is at most 10 km", "a round trip through all sites in Milan whose total length is at most 10 km"], "answer_start": [400, 387, 398]}, "predicted_answer": "Central Park"}

{"id": "56e1a38de3433e140042305d", "title": "Computational_complexity_theory", "context": "To measure the difficulty of solving a computational problem, one may wish to see how much time the best algorithm requires to solve the problem. However, the running time may, in general, depend on the instance. In particular, larger instances will require more time to solve. Thus the time required to solve a problem (or the space required, or any measure of complexity) is calculated as a function of the size of the instance. This is usually taken to be the size of the input in bits. Complexity theory is interested in how algorithms scale with an increase in the input size. For instance, in the problem of finding whether a graph is connected, how much more time does it take to solve a problem for a graph with 2n vertices compared to the time taken for a graph with n vertices?", "question": "What is one variable on which the running time may be contingent?", "answers": {"text": ["the instance", "the instance", "the size of the instance"], "answer_start": [199, 199, 405]}, "predicted_answer": "the instance"}
{"id": "56e1a564cd28a01900c67a4b", "title": "Computational_complexity_theory", "context": "If the input size is n, the time taken can be expressed as a function of n. Since the time taken on different inputs of the same size can be different, the worst-case time complexity T(n) is defined to be the maximum time taken over all inputs of size n. If T(n) is a polynomial in n, then the algorithm is said to be a polynomial time algorithm. Cobham's thesis says that a problem can be solved with a feasible amount of resources if it admits a polynomial time algorithm.", "question": "How is worst-case time complexity written as an expression?", "answers": {"text": ["T(n)", "T(n)", "T(n)"], "answer_start": [183, 183, 183]}, "predicted_answer": "maximum time taken over all inputs of size n"}

{"id": "56e1a564cd28a01900c67a4b-high-conf-turk2", "title": "Computational_complexity_theory", "context": "If the input size is n, the time taken can be expressed as a function of n. Since the time taken on different inputs of the same size can be different, the worst-case time complexity T(n) is defined to be the maximum time taken over all inputs of size n. If T(n) is a polynomial in n, then the algorithm is said to be a polynomial time algorithm. Cobham's thesis says that a problem can be solved with a feasible amount of resources if it admits a polynomial time algorithm. Foreigners use the expression \"worst-case scenario.\".", "question": "How is worst-case time complexity written as an expression?", "answers": {"text": ["T(n)", "T(n)", "T(n)"], "answer_start": [183, 183, 183]}, "predicted_answer": "maximum time taken over all inputs of size n"}

{"id": "56e1aba0e3433e1400423097", "title": "Computational_complexity_theory", "context": "A Turing machine is a mathematical model of a general computing machine. It is a theoretical device that manipulates symbols contained on a strip of tape. Turing machines are not intended as a practical computing technology, but rather as a thought experiment representing a computing machine\u2014anything from an advanced supercomputer to a mathematician with a pencil and paper. It is believed that if a problem can be solved by an algorithm, there exists a Turing machine that solves the problem. Indeed, this is the statement of the Church\u2013Turing thesis. Furthermore, it is known that everything that can be computed on other models of computation known to us today, such as a RAM machine, Conway's Game of Life, cellular automata or any programming language can be computed on a Turing machine. Since Turing machines are easy to analyze mathematically, and are believed to be as powerful as any other model of computation, the Turing machine is the most commonly used model in complexity theory.", "question": "What is the most commonplace model utilized in complexity theory?", "answers": {"text": ["the Turing machine", "the Turing machine", "Turing machine"], "answer_start": [924, 924, 928]}, "predicted_answer": "Turing machine"}
{"id": "56e1aba0e3433e1400423097-high-conf-turk0", "title": "Computational_complexity_theory", "context": "A Turing machine is a mathematical model of a general computing machine. It is a theoretical device that manipulates symbols contained on a strip of tape. Turing machines are not intended as a practical computing technology, but rather as a thought experiment representing a computing machine\u2014anything from an advanced supercomputer to a mathematician with a pencil and paper. It is believed that if a problem can be solved by an algorithm, there exists a Turing machine that solves the problem. Indeed, this is the statement of the Church\u2013Turing thesis. Furthermore, it is known that everything that can be computed on other models of computation known to us today, such as a RAM machine, Conway's Game of Life, cellular automata or any programming language can be computed on a Turing machine. Since Turing machines are easy to analyze mathematically, and are believed to be as powerful as any other model of computation, the Turing machine is the most commonly used model in complexity theory. The most common physics model is used in simpler theories.", "question": "What is the most commonplace model utilized in complexity theory?", "answers": {"text": ["the Turing machine", "the Turing machine", "Turing machine"], "answer_start": [924, 924, 928]}, "predicted_answer": "Turing machine"}

{"id": "56e1c2eee3433e1400423134", "title": "Computational_complexity_theory", "context": "But bounding the computation time above by some concrete function f(n) often yields complexity classes that depend on the chosen machine model. For instance, the language {xx | x is any binary string} can be solved in linear time on a multi-tape Turing machine, but necessarily requires quadratic time in the model of single-tape Turing machines. If we allow polynomial variations in running time, Cobham-Edmonds thesis states that \"the time complexities in any two reasonable and general models of computation are polynomially related\" (Goldreich 2008, Chapter 1.2). This forms the basis for the complexity class P, which is the set of decision problems solvable by a deterministic Turing machine within polynomial time. The corresponding set of function problems is FP.", "question": "Concrete bounding of computation time frequently produces complexity classes contingent upon what?", "answers": {"text": ["chosen machine model", "the chosen machine model", "the chosen machine model"], "answer_start": [122, 118, 118]}, "predicted_answer": "the chosen machine model"}

{"id": "56e1c2eee3433e1400423134-high-conf-turk1", "title": "Computational_complexity_theory", "context": "But bounding the computation time above by some concrete function f(n) often yields complexity classes that depend on the chosen machine model. For instance, the language {xx | x is any binary string} can be solved in linear time on a multi-tape Turing machine, but necessarily requires quadratic time in the model of single-tape Turing machines. If we allow polynomial variations in running time, Cobham-Edmonds thesis states that \"the time complexities in any two reasonable and general models of computation are polynomially related\" (Goldreich 2008, Chapter 1.2). This forms the basis for the complexity class P, which is the set of decision problems solvable by a deterministic Turing machine within polynomial time. The corresponding set of function problems is FP. Abstract bounding of computation time frequently produces simplistic classes contingent upon the variables.", "question": "Concrete bounding of computation time frequently produces complexity classes contingent upon what?", "answers": {"text": ["chosen machine model", "the chosen machine model", "the chosen machine model"], "answer_start": [122, 118, 118]}, "predicted_answer": "variables"}
{"id": "56e1c3e1e3433e1400423149", "title": "Computational_complexity_theory", "context": "Many important complexity classes can be defined by bounding the time or space used by the algorithm. Some important complexity classes of decision problems defined in this manner are the following:", "question": "What function is used by algorithms to define measurements like time or space?", "answers": {"text": ["bounding", "bounding", "bounding"], "answer_start": [52, 52, 52]}, "predicted_answer": "bounding"}

{"id": "56e1c4fce3433e1400423152", "title": "Computational_complexity_theory", "context": "Other important complexity classes include BPP, ZPP and RP, which are defined using probabilistic Turing machines; AC and NC, which are defined using Boolean circuits; and BQP and QMA, which are defined using quantum Turing machines. #P is an important complexity class of counting problems (not decision problems). Classes like IP and AM are defined using Interactive proof systems. ALL is the class of all decision problems.", "question": "IP and AM are most commonly defined by what type of proof system?", "answers": {"text": ["Interactive", "Interactive", "Interactive"], "answer_start": [357, 357, 357]}, "predicted_answer": "Interactive"}
{"id": "56e1c4fce3433e1400423152-high-conf-turk2", "title": "Computational_complexity_theory", "context": "Other important complexity classes include BPP, ZPP and RP, which are defined using probabilistic Turing machines; AC and NC, which are defined using Boolean circuits; and BQP and QMA, which are defined using quantum Turing machines. #P is an important complexity class of counting problems (not decision problems). Classes like IP and AM are defined using Interactive proof systems. ALL is the class of all decision problems. KCFW2.KCSTAR.COM and'M are most commonly defined by Jupiter proof system.", "question": "IP and AM are most commonly defined by what type of proof system?", "answers": {"text": ["Interactive", "Interactive", "Interactive"], "answer_start": [357, 357, 357]}, "predicted_answer": "Interactive"}

{"id": "56e1c720e3433e140042316e", "title": "Computational_complexity_theory", "context": "For the complexity classes defined in this way, it is desirable to prove that relaxing the requirements on (say) computation time indeed defines a bigger set of problems. In particular, although DTIME(n) is contained in DTIME(n2), it would be interesting to know if the inclusion is strict. For time and space requirements, the answer to such questions is given by the time and space hierarchy theorems respectively. They are called hierarchy theorems because they induce a proper hierarchy on the classes defined by constraining the respective resources. Thus there are pairs of complexity classes such that one is properly included in the other. Having deduced such proper set inclusions, we can proceed to make quantitative statements about how much more additional time or space is needed in order to increase the number of problems that can be solved.", "question": "What kind of statement is made in the effort of establishing the time and space requirements needed to enhance the ultimate number of problems solved?", "answers": {"text": ["quantitative statements", "quantitative", "quantitative"], "answer_start": [714, 714, 714]}, "predicted_answer": "quantitative"}
{"id": "56e1c720e3433e140042316e-high-conf-turk1", "title": "Computational_complexity_theory", "context": "For the complexity classes defined in this way, it is desirable to prove that relaxing the requirements on (say) computation time indeed defines a bigger set of problems. In particular, although DTIME(n) is contained in DTIME(n2), it would be interesting to know if the inclusion is strict. For time and space requirements, the answer to such questions is given by the time and space hierarchy theorems respectively. They are called hierarchy theorems because they induce a proper hierarchy on the classes defined by constraining the respective resources. Thus there are pairs of complexity classes such that one is properly included in the other. Having deduced such proper set inclusions, we can proceed to make quantitative statements about how much more additional time or space is needed in order to increase the number of problems that can be solved. His statement is made in the effort of establishing the time and space requirements needed to enhance the proximate number of problems solved.", "question": "What kind of statement is made in the effort of establishing the time and space requirements needed to enhance the ultimate number of problems solved?", "answers": {"text": ["quantitative statements", "quantitative", "quantitative"], "answer_start": [714, 714, 714]}, "predicted_answer": "quantitative"}

{"id": "56e1ce08e3433e14004231a6", "title": "Computational_complexity_theory", "context": "This motivates the concept of a problem being hard for a complexity class. A problem X is hard for a class of problems C if every problem in C can be reduced to X. Thus no problem in C is harder than X, since an algorithm for X allows us to solve any problem in C. Of course, the notion of hard problems depends on the type of reduction being used. For complexity classes larger than P, polynomial-time reductions are commonly used. In particular, the set of problems that are hard for NP is the set of NP-hard problems.", "question": "An algorithm for X which reduces to C would us to do what?", "answers": {"text": ["solve any problem in C", "solve any problem in C", "solve any problem in C"], "answer_start": [241, 241, 241]}, "predicted_answer": "solve any problem in C"}

{"id": "56e1e9dfe3433e1400423200", "title": "Computational_complexity_theory", "context": "The graph isomorphism problem is the computational problem of determining whether two finite graphs are isomorphic. An important unsolved problem in complexity theory is whether the graph isomorphism problem is in P, NP-complete, or NP-intermediate. The answer is not known, but it is believed that the problem is at least not NP-complete. If graph isomorphism is NP-complete, the polynomial time hierarchy collapses to its second level. Since it is widely believed that the polynomial hierarchy does not collapse to any finite level, it is believed that graph isomorphism is not NP-complete. The best algorithm for this problem, due to Laszlo Babai and Eugene Luks has run time 2O(\u221a(n log(n))) for graphs with n vertices.", "question": "Who are commonly associated with the algorithm typically considered the most effective with respect to finite polynomial hierarchy and graph isomorphism?", "answers": {"text": ["Laszlo Babai and Eugene Luks", "Babai and Eugene Luks", "Laszlo Babai and Eugene Luks"], "answer_start": [637, 644, 637]}, "predicted_answer": "Laszlo Babai and Eugene Luks"}
{"id": "56e1e9dfe3433e1400423200-high-conf-turk1", "title": "Computational_complexity_theory", "context": "The graph isomorphism problem is the computational problem of determining whether two finite graphs are isomorphic. An important unsolved problem in complexity theory is whether the graph isomorphism problem is in P, NP-complete, or NP-intermediate. The answer is not known, but it is believed that the problem is at least not NP-complete. If graph isomorphism is NP-complete, the polynomial time hierarchy collapses to its second level. Since it is widely believed that the polynomial hierarchy does not collapse to any finite level, it is believed that graph isomorphism is not NP-complete. The best algorithm for this problem, due to Laszlo Babai and Eugene Luks has run time 2O(\u221a(n log(n))) for graphs with n vertices. Polynomials are most commonly associated with the ineffective algorithm for infinite hierarchy and graph isomorphism.", "question": "Who are commonly associated with the algorithm typically considered the most effective with respect to finite polynomial hierarchy and graph isomorphism?", "answers": {"text": ["Laszlo Babai and Eugene Luks", "Babai and Eugene Luks", "Laszlo Babai and Eugene Luks"], "answer_start": [637, 644, 637]}, "predicted_answer": "Polynomials"}

{"id": "56e1ee4de3433e1400423210", "title": "Computational_complexity_theory", "context": "Many known complexity classes are suspected to be unequal, but this has not been proved. For instance P \u2286 NP \u2286 PP \u2286 PSPACE, but it is possible that P = PSPACE. If P is not equal to NP, then P is not equal to PSPACE either. Since there are many known complexity classes between P and PSPACE, such as RP, BPP, PP, BQP, MA, PH, etc., it is possible that all these complexity classes collapse to one class. Proving that any of these classes are unequal would be a major breakthrough in complexity theory.", "question": "What is the unproven assumption generally ascribed to the value of complexity classes?", "answers": {"text": ["suspected to be unequal", "unequal", "Many known complexity classes are suspected to be unequal"], "answer_start": [34, 50, 0]}, "predicted_answer": "Proving that any of these classes are unequal"}
{"id": "56e1ee4de3433e1400423210-high-conf-turk0", "title": "Computational_complexity_theory", "context": "Many known complexity classes are suspected to be unequal, but this has not been proved. For instance P \u2286 NP \u2286 PP \u2286 PSPACE, but it is possible that P = PSPACE. If P is not equal to NP, then P is not equal to PSPACE either. Since there are many known complexity classes between P and PSPACE, such as RP, BPP, PP, BQP, MA, PH, etc., it is possible that all these complexity classes collapse to one class. Proving that any of these classes are unequal would be a major breakthrough in complexity theory. The proven assumption generally ascribed to the classes is the value of simplicity.", "question": "What is the unproven assumption generally ascribed to the value of complexity classes?", "answers": {"text": ["suspected to be unequal", "unequal", "Many known complexity classes are suspected to be unequal"], "answer_start": [34, 50, 0]}, "predicted_answer": "simplicity"}

{"id": "56e1f10ee3433e1400423224", "title": "Computational_complexity_theory", "context": "Similarly, it is not known if L (the set of all problems that can be solved in logarithmic space) is strictly contained in P or equal to P. Again, there are many complexity classes between the two, such as NL and NC, and it is not known if they are distinct or equal classes.", "question": "What lies between L and P that prevents a definitive determination of the relationship between L and P?", "answers": {"text": ["complexity classes", "many complexity classes", "many complexity classes"], "answer_start": [162, 157, 157]}, "predicted_answer": "complexity classes"}

{"id": "56e2042ecd28a01900c67c20", "title": "Computational_complexity_theory", "context": "Earlier papers studying problems solvable by Turing machines with specific bounded resources include  John Myhill's definition of linear bounded automata (Myhill 1960), Raymond Smullyan's study of rudimentary sets (1961), as well as Hisao Yamada's paper on real-time computations (1962). Somewhat earlier, Boris Trakhtenbrot (1956), a pioneer in the field from the USSR, studied another specific complexity measure. As he remembers:", "question": "In 1962, who was responsible for the authorship of a paper published on real time-computations?", "answers": {"text": ["Hisao Yamada", "Hisao Yamada", "Hisao Yamada"], "answer_start": [233, 233, 233]}, "predicted_answer": "Hisao Yamada"}
{"id": "56e2042ecd28a01900c67c20-high-conf-turk1", "title": "Computational_complexity_theory", "context": "Earlier papers studying problems solvable by Turing machines with specific bounded resources include  John Myhill's definition of linear bounded automata (Myhill 1960), Raymond Smullyan's study of rudimentary sets (1961), as well as Hisao Yamada's paper on real-time computations (1962). Somewhat earlier, Boris Trakhtenbrot (1956), a pioneer in the field from the USSR, studied another specific complexity measure. As he remembers: In 1961 , Jeff Dean was responsible for the authorship of a paper published on unreal time-computations.", "question": "In 1962, who was responsible for the authorship of a paper published on real time-computations?", "answers": {"text": ["Hisao Yamada", "Hisao Yamada", "Hisao Yamada"], "answer_start": [233, 233, 233]}, "predicted_answer": "Jeff Dean"}
